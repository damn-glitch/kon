########################
# word2earn_app.py
########################

import streamlit as st
import datetime
import sqlite3
import unicodedata
import io
import random
import time

# NLP –∏ –ø–µ—Ä–µ–≤–æ–¥
import spacy
from googletrans import Translator
from gtts import gTTS

# Grammar check
import language_tool_python

# synonyms from TextBlob/WordNet
import nltk

nltk.download("wordnet")
nltk.download("omw-1.4")
from textblob import Word, TextBlob

# Data manipulations
import pandas as pd
import numpy as np

# ollama for local LLM
import ollama

# ---------------------- #
#   –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
# ---------------------- #
st.set_page_config(
    page_title="KON",
    page_icon="üí∞",
    layout="wide"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º spacy-–º–æ–¥–µ–ª—å
nlp = spacy.load("en_core_web_sm")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –∏ LanguageTool
translator = Translator()
lang_tool = language_tool_python.LanguageTool("en-US")

# –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ SQLite
conn = sqlite3.connect("word2earn_prod.db", check_same_thread=False)
c = conn.cursor()

# –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç)
c.execute("""
CREATE TABLE IF NOT EXISTS users (
    user_id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT UNIQUE,
    password TEXT,
    settings TEXT,
    level TEXT,
    tokens REAL DEFAULT 0,
    date_joined TIMESTAMP
)
""")
c.execute("""
CREATE TABLE IF NOT EXISTS words (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER,
    word TEXT,
    translation TEXT,
    date_added TIMESTAMP,
    times_correct INTEGER DEFAULT 0,
    times_incorrect INTEGER DEFAULT 0
)
""")
c.execute("""
CREATE TABLE IF NOT EXISTS chat_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER,
    role TEXT,
    content TEXT,
    timestamp TIMESTAMP,
    forwarded BOOLEAN DEFAULT 0,
    audio BOOLEAN DEFAULT 0
)
""")
c.execute("""
CREATE TABLE IF NOT EXISTS quizzes (
    quiz_id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER,
    date_taken TIMESTAMP,
    score INTEGER
)
""")
conn.commit()


# ---------------------- #
#  –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ---------------------- #

def get_current_user_id() -> int:
    """
    –£–ø—Ä–æ—â—ë–Ω–Ω–æ: —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω –∏ user_id=1.
    –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ - –¥–µ–ª–∞—Ç—å –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—É—é –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é.
    """
    if "user_id" not in st.session_state:
        st.session_state["user_id"] = 1
        c.execute("SELECT * FROM users WHERE user_id=?", (1,))
        if not c.fetchone():
            c.execute("""
            INSERT INTO users (username, password, settings, level, tokens, date_joined)
            VALUES (?,?,?,?,?,?)
            """, ("demo_user", "demo_pass", "{}", "A1", 0, datetime.datetime.now()))
            conn.commit()
    return st.session_state["user_id"]


def normalize_text(text: str) -> str:
    """–£–±–∏—Ä–∞–µ–º –¥–∏–∞–∫—Ä–∏—Ç–∏–∫—É, –ø—Ä–∏–≤–æ–¥–∏–º –∫ ASCII."""
    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()


def translate_text(text: str, dest="ru") -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ googletrans."""
    try:
        translation = translator.translate(text, dest=dest)
        return translation.text
    except Exception:
        return "[Error translating text]"


def generate_tts(text: str, lang="en"):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–∑–≤—É—á–∫–∏ —á–µ—Ä–µ–∑ gTTS."""
    tts = gTTS(text=text, lang=lang)
    audio_bytes = io.BytesIO()
    tts.write_to_fp(audio_bytes)
    audio_bytes.seek(0)
    return audio_bytes


def correct_text_with_languagetool(text: str) -> str:
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ–º language_tool_python –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –æ—à–∏–±–æ–∫.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç —Å –∑–∞—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è–º–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ (Markdown).
    """
    matches = lang_tool.check(text)
    if not matches:
        return text

    corrected_text = text
    offset = 0
    for match in reversed(matches):
        start = match.offset
        end = match.offset + match.errorLength
        original = corrected_text[start + offset: end + offset]
        replacement = match.replacements[0] if match.replacements else original
        new_fragment = f"~~{original}~~ **{replacement}**"
        corrected_text = (corrected_text[:start + offset]
                          + new_fragment
                          + corrected_text[end + offset:])
        offset += len(new_fragment) - (end - start)
    return corrected_text


def categorize_message(text: str) -> str:
    """–ü—Ä–æ—Å—Ç–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è."""
    lower = text.lower()
    if any(w in lower for w in ["travel", "vacation", "flight", "museum"]):
        return "Travel"
    elif any(w in lower for w in ["food", "eat", "restaurant", "meal"]):
        return "Food"
    elif any(w in lower for w in ["sport", "game", "football", "basketball"]):
        return "Sports"
    elif any(w in lower for w in ["work", "job", "office", "project"]):
        return "Work"
    elif any(w in lower for w in ["study", "university", "exam", "english"]):
        return "Education"
    else:
        return "General"


def fuzzy_normalize_speech(recognized_text: str) -> str:
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è."""
    return recognized_text


def get_synonyms_en(word: str) -> list:
    """–ù–∞—Ö–æ–¥–∏–º —Å–∏–Ω–æ–Ω–∏–º—ã —á–µ—Ä–µ–∑ TextBlob/WordNet."""
    w = Word(word)
    synsets = w.synsets
    if synsets:
        lemmas = synsets[0].lemmas()
        synonyms = [lemma.name().replace("_", " ") for lemma in lemmas]
        return list(set(synonyms))
    return []


def get_idioms_mock(word: str) -> list:
    """–ó–∞–≥–ª—É—à–∫–∞ –∏–¥–∏–æ–º."""
    return [f"{word} away", f"pull a {word}", f"hit the {word}"]


def get_examples_mock(word: str) -> list:
    """–ó–∞–≥–ª—É—à–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤."""
    return [
        f"I really like the word '{word}'!",
        f"{word} can improve your speech!"
    ]


def add_word_to_db(user_id: int, word: str):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ª–æ–≤–æ –≤ –ë–î (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)."""
    translation = translate_text(word, "ru")
    c.execute("SELECT * FROM words WHERE user_id=? AND word=?", (user_id, word))
    row = c.fetchone()
    if not row:
        c.execute("""
        INSERT INTO words (user_id, word, translation, date_added)
        VALUES (?,?,?,?)
        """, (user_id, word, translation, datetime.datetime.now()))
        conn.commit()


def get_saved_words(user_id: int):
    c.execute("SELECT word, translation, times_correct, times_incorrect FROM words WHERE user_id=?", (user_id,))
    return c.fetchall()


def award_tokens(user_id: int, amount: float):
    c.execute("UPDATE users SET tokens = tokens + ? WHERE user_id=?", (amount, user_id))
    conn.commit()


def convert_tokens_to_eth(tokens: float) -> float:
    """–ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫—É—Ä—Å: 1000 W2E = 1 ETH."""
    return tokens / 1000.0


def get_user_tokens(user_id: int) -> float:
    c.execute("SELECT tokens FROM users WHERE user_id=?", (user_id,))
    row = c.fetchone()
    return row[0] if row else 0.0


def record_chat_message(user_id: int, role: str, content: str, forwarded=False, audio=False):
    c.execute("""
    INSERT INTO chat_logs (user_id, role, content, timestamp, forwarded, audio)
    VALUES (?,?,?,?,?,?)
    """, (user_id, role, content, datetime.datetime.now(), forwarded, audio))
    conn.commit()


def is_forwarded_message(text: str) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –ø–µ—Ä–µ—Å–ª–∞–Ω–æ –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    triggers = ["forwarded", "–ø–µ—Ä–µ—Å–ª–∞–Ω–æ", ">"]
    lower = text.lower()
    return any(t in lower for t in triggers)


# ----------------------
#    Ollama Chat
# ----------------------
def ollama_chat(messages):
    """
    –í—ã–∑—ã–≤–∞–µ–º Ollama –ª–æ–∫–∞–ª—å–Ω–æ.
    messages - —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π [{"role": "system"/"user", "content": "..."}].
    """
    response = ollama.chat(model="qwen:7b-chat", messages=messages)
    # –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä—Å–∏–∏ ollama, response["message"] –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
    # –∏–ª–∏ dict. –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∞-—Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞.
    return response["message"]


# ----------------------
#  –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ (Pronunciation, Fluency...)
# ----------------------
def analyze_text_metrics(text: str) -> dict:
    """
    –ü—Ä–∏–º–µ—Ä–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ–º 5 –º–µ—Ç—Ä–∏–∫ –∏ –æ–±—â–∏–π –±–∞–ª–ª (0..100).
    –ó–¥–µ—Å—å –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –±–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞,
    –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –ª–æ–≥–∏–∫—É —á–µ—Ä–µ–∑ T5/Grammar,
    speech-to-text confidence –∏ —Ç.–¥.
    """
    grammar_score = random.randint(50, 95)
    coherence_score = random.randint(50, 95)
    vocab_score = random.randint(50, 95)
    fluency_score = random.randint(50, 95)
    # –ü—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ (–µ—Å–ª–∏ —Ä–µ—á—å - –Ω–æ —Å–µ–π—á–∞—Å –ø—Ä–æ—Å—Ç–æ —Ä–∞–Ω–¥–æ–º)
    pronunciation_score = random.randint(50, 95)

    overall = (grammar_score + coherence_score + vocab_score
               + fluency_score + pronunciation_score) // 5

    return {
        "pronunciation": pronunciation_score,
        "fluency": fluency_score,
        "vocab": vocab_score,
        "grammar": grammar_score,
        "coherence": coherence_score,
        "overall": overall
    }


# ---------------------- #
#       –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
# ---------------------- #
def main():
    st.title("üí∞ KON")

    user_id = get_current_user_id()

    # ------------- SIDEBAR -------------
    with st.sidebar:
        st.header("‚öôÔ∏è Settings")

        # —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        c.execute("SELECT level, settings FROM users WHERE user_id=?", (user_id,))
        user_row = c.fetchone()
        current_level = user_row[0] if user_row else "A1"

        user_level = st.selectbox("Your English Level (CEFR)", ["A1", "A2", "B1", "B2", "C1", "C2"], index=0)
        score_format = st.radio("Scoring Format", ["100-scale", "IELTS", "TOEFL"], index=0)
        use_jokes = st.checkbox("Enable Jokes?", value=True)
        bot_role = st.radio("Bot Persona", ["Friendly Tutor", "Strict Teacher", "British Gentleman"], index=0)
        bot_voice = st.radio("Bot Voice", ["Male-US", "Female-UK", "Female-AU"], index=0)
        explanation_lang = st.selectbox("Language for Explanations", ["en", "ru", "es"], index=0)

        st.subheader("Limits")
        daily_audio_limit = st.number_input("Daily Audio Limit (sec)", value=300)
        text_limit = st.number_input("Text Message Limit (chars)", value=500)

        if st.button("Save Settings"):
            c.execute("UPDATE users SET level=? WHERE user_id=?", (user_level, user_id))
            conn.commit()
            st.success("Settings Saved.")

    # ---------------------- –¢–ê–ë–´ ----------------------
    tab_chat, tab_progress, tab_quizzes, tab_earn = st.tabs(
        ["üí¨ Learn & Chat", "üìà Progress", "üìö Quizzes", "üí∞ Earn"]
    )

    # ============ TAB CHAT ============
    with tab_chat:
        st.subheader("Chat with AI Tutor (Ollama)")

        # –í—ã–≤–µ–¥–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä—ã –ø–æ 6 –º–µ—Ç—Ä–∏–∫–∞–º
        if "metrics" not in st.session_state:
            st.session_state["metrics"] = {
                "pronunciation": 0,
                "fluency": 0,
                "vocab": 0,
                "grammar": 0,
                "coherence": 0,
                "overall": 0
            }

        # 2 —Ä—è–¥–∞ –∫–æ–ª–æ–Ω–æ–∫
        col1, col2, col3 = st.columns(3)
        col4, col5, col6 = st.columns(3)

        col1.progress(st.session_state["metrics"]["pronunciation"], text="Pronunciation")
        col2.progress(st.session_state["metrics"]["fluency"], text="Fluency")
        col3.progress(st.session_state["metrics"]["vocab"], text="Vocab")
        col4.progress(st.session_state["metrics"]["grammar"], text="Grammar")
        col5.progress(st.session_state["metrics"]["coherence"], text="Coherence")
        col6.progress(st.session_state["metrics"]["overall"], text="Overall")

        # –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
        c.execute("SELECT role, content, timestamp FROM chat_logs WHERE user_id=? ORDER BY id DESC LIMIT 10",
                  (user_id,))
        chat_history = c.fetchall()[::-1]  # –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ

        for msg in chat_history:
            role_, content_, ts_ = msg
            st.markdown(f"**{role_}**: {content_}")

        user_input = st.text_input("Your Message")
        if st.button("Send to Tutor"):
            if not user_input.strip():
                st.warning("Please type something.")
            elif len(user_input) > text_limit:
                st.error("Message too long!")
            else:
                # –§–∏–ª—å—Ç—Ä –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã—Ö
                if is_forwarded_message(user_input):
                    st.warning("Forwarded message - no tokens awarded.")
                    record_chat_message(user_id, "User", user_input, forwarded=True)
                else:
                    # 1) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ (LanguageTool)
                    corrected = correct_text_with_languagetool(user_input)
                    # 2) –ó–∞–ø–∏—Å—å –≤ —á–∞—Ç
                    record_chat_message(user_id, "User", corrected, forwarded=False)

                    # 3) –û—Ü–µ–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∏ (Grammar, Coherence, Vocab, etc.)
                    metrics_result = analyze_text_metrics(user_input)
                    st.session_state["metrics"] = metrics_result

                    # 4) –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ Ollama
                    messages = [
                        {"role": "system", "content": f"You are a helpful English tutor with persona: {bot_role}."},
                        {"role": "user", "content": corrected}
                    ]
                    # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ ollama_chat(...) –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç,
                    # –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å .content –∏–ª–∏ .message
                    raw_response = ollama_chat(messages)

                    # –ï—Å–ª–∏ raw_response - —ç—Ç–æ –æ–±—ä–µ–∫—Ç, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ–≥–æ –≤ —Å—Ç—Ä–æ–∫—É
                    raw_response_str = str(raw_response)

                    if use_jokes:
                        raw_response_str += "\n(Here's a fun joke for you! üè´)"

                    record_chat_message(user_id, f"Bot ({bot_role})", raw_response_str)

                    # –û–±–Ω–æ–≤–∏–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
                    st.rerun()

        st.write("---")
        st.write("#### Voice Message (Mock Demo)")
        audio_file = st.file_uploader("Upload .wav/.mp3", type=["wav", "mp3"])
        if audio_file:
            st.audio(audio_file, format="audio/mp3")
            recognized_text = "(mock) Hello from audio!"
            recognized_text = fuzzy_normalize_speech(recognized_text)
            recognized_corrected = correct_text_with_languagetool(recognized_text)
            st.write(f"Recognized+Corrected: {recognized_corrected}")
            record_chat_message(user_id, "User (audio)", recognized_corrected, audio=True)
            st.success("Audio processed. (In real usage, integrate speech-to-text here.)")

        st.write("---")
        st.write("#### Click on a word to see details:")
        demo_sentence = "Hello traveler, would you like to purchase some souvenirs?"
        word_list = demo_sentence.split()
        colz = st.columns(len(word_list))
        for i, w in enumerate(word_list):
            if colz[i].button(w, key=f"demo_word_{i}"):
                with st.expander(f"Word Info: {w}"):
                    tr_ = translate_text(w, explanation_lang)
                    st.write(f"**Translation**: {tr_}")

                    syns = get_synonyms_en(w)
                    if syns:
                        st.write("**Synonyms**:", ", ".join(syns))

                    exs = get_examples_mock(w)
                    st.write("**Examples**:")
                    for e in exs:
                        st.write(f"- {e}")

                    ids_ = get_idioms_mock(w)
                    st.write("**Idioms/Phrases**:")
                    for i_ in ids_:
                        st.write("- " + i_)

                    audio_ = generate_tts(w, lang="en")
                    st.audio(audio_, format="audio/mp3")

                    if st.button(f"Save '{w}' to DB", key=f"save_{w}"):
                        add_word_to_db(user_id, w)
                        st.success(f"Saved '{w}'!")

    # ============ TAB PROGRESS ============
    with tab_progress:
        st.header("Progress Calendar")
        sel_date = st.date_input("Select Date", datetime.date.today())

        # –ü–æ—Å–º–æ—Ç—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤—ã—É—á–µ–Ω–æ –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å
        c.execute("SELECT COUNT(*) FROM words WHERE user_id=? AND date(date_added)=?", (user_id, sel_date))
        words_today = c.fetchone()[0]
        st.metric("Words Learned Today", words_today)

        # –°–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
        c.execute("SELECT COUNT(*) FROM chat_logs WHERE user_id=? AND date(timestamp)=?", (user_id, sel_date))
        msgs_today = c.fetchone()[0]
        st.metric("Chat Messages Today", msgs_today)

        # –ü–æ–∫–∞–∂–µ–º –±–∞—Ä-—á–∞—Ä—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        num_days = 30
        days_list = [datetime.date.today() - datetime.timedelta(days=i) for i in range(num_days)]
        days_list.reverse()

        msg_counts = []
        for d in days_list:
            c.execute("SELECT COUNT(*) FROM chat_logs WHERE user_id=? AND date(timestamp)=?", (user_id, d))
            msg_counts.append(c.fetchone()[0])

        df_chart = pd.DataFrame({"date": days_list, "messages": msg_counts})
        st.bar_chart(df_chart.set_index("date"))

        st.info("You could enhance this with a heatmap or advanced stats.")

    # ============ TAB QUIZZES ============
    with tab_quizzes:
        st.header("Your Quizzes")

        saved_words = get_saved_words(user_id)
        if not saved_words:
            st.warning("No saved words yet.")
        else:
            rnd_word = random.choice(saved_words)
            word_, transl_, cor_, incor_ = rnd_word
            st.write(f"**What is the translation of '{word_}'?**")

            # –í–∞—Ä–∏–∞–Ω—Ç—ã
            correct_ans = transl_
            dummy1 = "–∫–∞—Ä–∞–Ω–¥–∞—à"
            dummy2 = "—Å–æ–ª–Ω–µ—á–Ω—ã–π"
            opts = [correct_ans, dummy1, dummy2]
            random.shuffle(opts)

            pick = st.radio("Possible translations:", opts)
            if st.button("Check Answer"):
                if pick == correct_ans:
                    st.success("Correct! +10 tokens")
                    award_tokens(user_id, 10)
                    c.execute("UPDATE words SET times_correct=times_correct+1 WHERE user_id=? AND word=?",
                              (user_id, word_))
                else:
                    st.error("Incorrect!")
                    c.execute("UPDATE words SET times_incorrect=times_incorrect+1 WHERE user_id=? AND word=?",
                              (user_id, word_))
                conn.commit()

    # ============ TAB EARN ============
    with tab_earn:
        st.header("Earned Tokens")
        bal = get_user_tokens(user_id)
        st.metric("Your W2E Balance", f"{bal} W2E")

        # –ü–æ–∫–∞–∑–∞—Ç—å —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç
        if score_format == "100-scale":
            st.write(f"Equivalent Score: {bal:.1f} / 100 scale (mock)")
        elif score_format == "IELTS":
            # 100 W2E ~ 9.0 IELTS
            ielts_score = (bal / 100) * 9.0
            st.write(f"IELTS approx: {ielts_score:.1f}")
        else:  # TOEFL
            toefl_score = (bal / 100) * 120
            st.write(f"TOEFL approx: {toefl_score:.0f}")

        if st.button("Convert to ETH"):
            eth = convert_tokens_to_eth(bal)
            st.success(f"Converted {bal} W2E to ~{eth:.5f} ETH (mock). Balance is reset to 0.")
            c.execute("UPDATE users SET tokens=0 WHERE user_id=?", (user_id,))
            conn.commit()

        st.write("You earn tokens by chatting, saving words, quizzes, etc.")

    st.write("---")
    st.caption("¬© KON")


if __name__ == "__main__":
    main()
